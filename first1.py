# -*- coding: utf-8 -*-
"""first1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1jym6Mm2T4Wj2b_AVu5p1EtWrPQ_wyEzJ

#**IMPORT REQUIRE LIBARIES**
"""

import pandas as pd
import numpy as nd
import seaborn as sns
import matplotlib.pyplot as plt

from google.colab import drive
drive.mount('/content/drive')

data=pd.read_csv('/content/drive/MyDrive/Colab Notebooks/diabetes.csv')
data.head()

data.describe()

data.info()

data.shape

data.isnull().values.any()

data.isnull().sum()

data.hist(bins=10,figsize=(10,10))
plt.show()

sns.heatmap(data.corr(),annot=True)

sns.countplot(x=data['Outcome'],palette='Blues_r')

x=data.drop("Outcome",axis=1)
y=data["Outcome"]

x.shape,y.shape

from sklearn.model_selection import train_test_split

"""#**SPLITTING OF DATA**"""

x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.25,random_state=109)

x_train.shape,y_train.shape,x_test.shape,y_test.shape

"""#**NAVIE BAYES**"""

from sklearn.naive_bayes import GaussianNB
from sklearn.metrics import accuracy_score
from sklearn.metrics import roc_auc_score
from sklearn.metrics import confusion_matrix
acc=[]
roc=[]
nb = GaussianNB()
nb.fit(x_train,y_train)
y_pred = nb.predict(x_test)
#accuracy score
ac=accuracy_score(y_test,y_pred)
acc.append(ac)
print("Accuracy Score:",ac)
#roc value
rc=roc_auc_score(y_test,y_pred)
roc.append(rc)
print("\n ROC score:",rc)

conf_nb = confusion_matrix(y_test,y_pred)
print(conf_nb)

from sklearn import metrics
print ("Classification Report on NaiveBayes\n")

# labels for set 1=True to upper left and 0 = False to lower right
print ("{0}".format(metrics.classification_report(y_test, y_pred, labels=[1, 0])))

from warnings import simplefilter
# ignore all future warnings
simplefilter(action='ignore', category=FutureWarning)

"""#**ADASYN**"""

from collections import Counter
x=data.iloc[:,:-1].values;
y=data.iloc[:,-1].values;
print("trian data:",x.shape)
print("test data:",y.shape)
print("original target value distribution:",Counter(y))

from imblearn.over_sampling import ADASYN
ada = ADASYN()
x_ada , y_ada = ada.fit_resample(x_train,y_train)
#plt.scatter(x_ada[:, 0], x_ada[:, -1], marker='o', c=Y_ada, s=500, edgecolor='k')
kwarg_params = {'linewidth': 1.5, 'edgecolor': 'black'}
colors = ['#A52A2A' if v == 0 else '#E5E4E2' if v == 1 else '#67a9cf' for v in y_ada]
plt.scatter(x_ada[:, 0], x_ada[:, -1], c=colors, s=190,**kwarg_params)
sns.despine()
plt.suptitle("Before adasyn completion over the data",fontsize = 'xx-large')

ada=ADASYN(sampling_strategy='minority',random_state=420,n_neighbors=5)
x_res,y_res=ada.fit_resample(x,y)
print(Counter(y_res))

ada = ADASYN()
x_ada , y_ada = ada.fit_resample(x_test,y_test)
#plt.scatter(x_ada[:, 0], x_ada[:, -1], marker='o', c=Y_ada, s=500, edgecolor='k')
kwarg_params = {'linewidth': 1.5, 'edgecolor': 'black'}
colors = ['#A52A2A' if v == 0 else '#E5E4E2' if v == 1 else '#67a9cf' for v in y_ada]
plt.scatter(x_ada[:, 0], x_ada[:, -1], c=colors, s=190,**kwarg_params)
sns.despine()
plt.suptitle("After adasyn completion over the data",fontsize = 'xx-large')

"""#**RANDOM FOREST**"""

from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score
from sklearn.metrics import roc_auc_score
rf = RandomForestClassifier(random_state=3)
rf.fit(x_train, y_train)
y_pred3 = rf.predict(x_test)
#accuracy score
ac=accuracy_score(y_test,y_pred3)
acc.append(ac)
print("Accuracy Score:",ac)
#roc score
rc=roc_auc_score(y_test,y_pred)
roc.append(rc)
print("\n ROC score:",rc)

conf_nb = confusion_matrix(y_test,y_pred3)
print(conf_nb)

print ("Classification Report on RandomForest\n")

# labels for set 1=True to upper left and 0 = False to lower right
print ("{0}".format(metrics.classification_report(y_test, y_pred3, labels=[1, 0])))

"""#**SVM**"""

from sklearn.svm import SVC
from sklearn.metrics import roc_auc_score
from sklearn.metrics import confusion_matrix,accuracy_score,make_scorer
from sklearn.model_selection import cross_validate

clf=SVC(kernel='linear')
clf.fit(x_train,y_train)
y_pred4=clf.predict(x_test)
#find accuracy
ac=accuracy_score(y_test,y_pred4)
acc.append(ac)
print("accyracy score:",ac)

#find the ROC_AOC curve
rc=roc_auc_score(y_test,y_pred4)
roc.append(rc)
print("\nROC score",rc)

conf_svm = confusion_matrix(y_test,y_pred4)
print(conf_svm)

print ("Classification Report on Svm\n")

# labels for set 1=True to upper left and 0 = False to lower right
print ("{0}".format(metrics.classification_report(y_test, y_pred4, labels=[1, 0])))

"""#**LOGISTIC REGRESSION**"""

from sklearn.linear_model import LogisticRegression
clf=LogisticRegression(solver='lbfgs', max_iter=1000)
clf.fit(x_train,y_train)
y_pred5=clf.predict(x_test)
#find accuracy
ac=accuracy_score(y_test,y_pred5)
acc.append(ac)
print("accuracy score:",ac)

#find the ROC_AOC curve
rc=roc_auc_score(y_test,y_pred5)
roc.append(rc)
print("\nROC score:",rc)

conf_log = confusion_matrix(y_test,y_pred5)
print(conf_log)

print ("Classification Report on LogisticRegresion\n")

# labels for set 1=True to upper left and 0 = False to lower right
print ("{0}".format(metrics.classification_report(y_test, y_pred5, labels=[1, 0])))

"""#**KNN**"""

from sklearn.neighbors import KNeighborsClassifier
clf=KNeighborsClassifier(n_neighbors=3)
clf.fit(x_train,y_train)
y_pred6=clf.predict(x_test)
#accuracy score
ac=accuracy_score(y_test,y_pred6)
acc.append(ac)
print("accuracy score:",ac)
#roc score
rc=roc_auc_score(y_test,y_pred6)
roc.append(rc)
print("\nROC score:",rc)

conf_knn = confusion_matrix(y_test,y_pred6)
print(conf_knn)

print ("Classification Report on Knn\n")

# labels for set 1=True to upper left and 0 = False to lower right
print ("{0}".format(metrics.classification_report(y_test, y_pred6, labels=[1, 0])))

ax=plt.figure(figsize=(9,4))
plt.bar(['Naive Bayes','Random Forest','SVM','Logistic Regression','KNN'],acc,label='Accuracy')
plt.ylabel('Accuracy Score')
plt.xlabel('\nAlgortihms')
plt.show()
#roc curve bar graph
ax=plt.figure(figsize=(9,4))
plt.bar(['Naivye Bayes','Random Forest','SVM','LogisticRegression','KNN'],roc,label='roc')
plt.ylabel('ROC AUC')
plt.xlabel('\nAlgortihms')
plt.show()

"""#**KFOLD VALIDATION**"""

from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
from sklearn.naive_bayes import GaussianNB
from sklearn.svm import SVC
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import KFold, cross_val_score

models = []
models.append(('LR', LogisticRegression(solver='lbfgs', max_iter=1000)))
models.append(('KNN', KNeighborsClassifier()))
models.append(('CART', DecisionTreeClassifier()))
models.append(('NB', GaussianNB()))
models.append(('SVM', SVC()))
models.append(('RF',RandomForestClassifier(random_state=4)))


results = []
names = []
scoring = 'accuracy'

for name, model in models:
    kfold = KFold(n_splits=10, random_state=7)
    cv_results = cross_val_score(model, x_res, y_res, cv=kfold, scoring=scoring)
    results.append(cv_results)
    names.append(name)
    msg = "%s: %f (%f)" % (name, cv_results.mean()*100, cv_results.std()*100)
    print(msg)